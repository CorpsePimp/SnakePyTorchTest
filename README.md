# SnakePyTorchTest

# Промпт для создания игры "Змейка" с самообучением на PyTorch Создай полную реализацию игры "Змейка" с самообучающимся ИИ в одном Python файле. Требования: ## Основные компоненты: 1. Игровая механика: Классическая змейка с движением, поеданием еды, ростом и столкновениями 2. Нейронная сеть: Deep Q-Network (DQN) на PyTorch для обучения агента 3. Обучение: Алгоритм Q-learning с experience replay и target network 4. Визуализация: Pygame для отображения игры и matplotlib для графиков обучения ## Технические детails: - Размер поля: 20x20 клеток - Входные данные для ИИ: 11 признаков (опасность в 3 направлениях, текущее направление движения, положение еды) - Выходные данные: 3 действия (прямо, поворот направо, поворот налево) - Архитектура сети: 3 полносвязных слоя (11 → 256 → 256 → 3) - Алгоритм обучения: Deep Q-Learning с ε-greedy exploration ## Функции обучения: - Experience replay buffer (размер 100,000) - Target network обновляется каждые 1000 шагов - Epsilon decay от 1.0 до 0.01 за 80 игр - Learning rate: 0.001 - Gamma (discount factor): 0.9 ## Система наград: - +10 за поедание еды - -10 за столкновение (смерть) - +1 за движение к еде - -1 за движение от еды - -1 за каждый шаг (стимул к быстрому поиску еды) ## Визуализация: - Игровое поле с змейкой (зеленая) и едой (красная) - Счетчик текущей игры, рекорда и среднего счета - График обучения (средний счет за последние 10 игр) - Возможность переключения между режимами (обучение/демонстрация) ## Дополнительные возможности: - Сохранение/загрузка обученной модели - Настройка скорости игры - Логирование процесса обучения - Возможность играть человеку (для сравнения) ## Структура файла: 1. Импорты библиотек 2. Константы и настройки 3. Класс игры Snake 4. Класс нейронной сети QNet 5. Класс агента QTrainer 6. Функции обучения и запуска 7. Основной цикл программы Код должен быть полностью рабочим, хорошо документированным и готовым к запуску. Включи подробные комментарии на русском языке для понимания логики работы.
